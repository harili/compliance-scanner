using Microsoft.Extensions.Logging;
using Microsoft.Extensions.Configuration;
using Microsoft.Extensions.DependencyInjection;
using ComplianceScannerPro.Core.Entities;
using ComplianceScannerPro.Shared.Enums;
using ComplianceScannerPro.Core.Interfaces;

namespace ComplianceScannerPro.Infrastructure.Services;

public class ScanService : IScanService
{
    private readonly IUnitOfWork _unitOfWork;
    private readonly IServiceScopeFactory _serviceScopeFactory;
    private readonly ILogger<ScanService> _logger;
    private readonly IConfiguration _configuration;

    public ScanService(
        IUnitOfWork unitOfWork,
        IServiceScopeFactory serviceScopeFactory,
        ILogger<ScanService> logger,
        IConfiguration configuration)
    {
        _unitOfWork = unitOfWork;
        _serviceScopeFactory = serviceScopeFactory;
        _logger = logger;
        _configuration = configuration;
    }

    public async Task<ScanResult> StartScanAsync(int websiteId, string userId)
    {
        var website = await _unitOfWork.Websites.GetByIdAsync(websiteId);
        if (website == null)
            throw new ArgumentException("Site web non trouv√©", nameof(websiteId));

        if (website.UserId != userId)
            throw new UnauthorizedAccessException("Acc√®s non autoris√© au site web");

        var scanResult = new ScanResult
        {
            ScanId = Guid.NewGuid().ToString(),
            WebsiteId = websiteId,
            Website = website,
            UserId = userId,
            StartedAt = DateTime.UtcNow,
            Status = ScanStatus.Pending
        };

        await _unitOfWork.ScanResults.AddAsync(scanResult);
        await _unitOfWork.SaveChangesAsync();

        // D√©marrer le scan en arri√®re-plan avec timeout et gestion d'erreurs
        _ = Task.Run(async () => 
        {
            using var scope = _serviceScopeFactory.CreateScope();
            var scopedLogger = scope.ServiceProvider.GetRequiredService<ILogger<ScanService>>();
            
            try
            {
                using var cts = new CancellationTokenSource(TimeSpan.FromMinutes(10)); // Timeout de 10 minutes
                await ExecuteScanAsync(scanResult.Id, cts.Token, scope.ServiceProvider);
            }
            catch (Exception ex)
            {
                scopedLogger.LogError(ex, "‚ùå [SCAN-CRITICAL] Erreur critique dans la t√¢che de scan {ScanId}", scanResult.ScanId);
                try
                {
                    var scopedUnitOfWork = scope.ServiceProvider.GetRequiredService<IUnitOfWork>();
                    var failedScan = await scopedUnitOfWork.ScanResults.GetByIdAsync(scanResult.Id);
                    if (failedScan != null)
                    {
                        await UpdateScanStatus(failedScan, ScanStatus.Failed, $"Erreur critique: {ex.Message}", scopedUnitOfWork);
                    }
                }
                catch (Exception updateEx)
                {
                    scopedLogger.LogError(updateEx, "‚ùå [SCAN-CRITICAL] Impossible de mettre √† jour le statut du scan √©chou√© {ScanId}", scanResult.ScanId);
                }
            }
        });

        _logger.LogInformation("Scan {ScanId} cr√©√© pour le site {WebsiteId}", scanResult.ScanId, websiteId);
        
        return scanResult;
    }

    public async Task<ScanResult?> GetScanResultAsync(string scanId)
    {
        return await _unitOfWork.ScanResults.GetAsync(s => s.ScanId == scanId);
    }

    public async Task<List<ScanResult>> GetUserScanHistoryAsync(string userId, int take = 10)
    {
        var scans = await _unitOfWork.ScanResults.GetAllAsync(s => s.UserId == userId);
        return scans.OrderByDescending(s => s.StartedAt).Take(take).ToList();
    }

    public async Task<bool> CanUserStartScanAsync(string userId)
    {
        // V√©rifier les scans en cours
        var runningScans = await _unitOfWork.ScanResults.GetAllAsync(s => 
            s.UserId == userId && 
            (s.Status == ScanStatus.Pending || s.Status == ScanStatus.Running));

        var maxConcurrentScans = int.Parse(_configuration["ScanSettings:MaxConcurrentScans"] ?? "2");
        
        if (runningScans.Count >= maxConcurrentScans)
        {
            _logger.LogWarning("Utilisateur {UserId} a atteint la limite de scans simultan√©s", userId);
            return false;
        }

        // V√©rifier les quotas d'abonnement (sera impl√©ment√© avec SubscriptionService)
        return true;
    }

    private async Task ExecuteScanAsync(int scanResultId, CancellationToken cancellationToken, IServiceProvider serviceProvider)
    {
        var logger = serviceProvider.GetRequiredService<ILogger<ScanService>>();
        var unitOfWork = serviceProvider.GetRequiredService<IUnitOfWork>();
        var webCrawler = serviceProvider.GetRequiredService<IWebCrawlerService>();
        var accessibilityAnalyzer = serviceProvider.GetRequiredService<IAccessibilityAnalyzer>();
        
        ScanResult? scanResult = null;
        
        try
        {
            logger.LogInformation("üöÄ [SCAN-START] D√©but ExecuteScanAsync pour scanResultId={ScanResultId}", scanResultId);
            
            scanResult = await unitOfWork.ScanResults.GetByIdAsync(scanResultId);
            if (scanResult == null)
            {
                logger.LogError("‚ùå [SCAN-ERROR] ScanResult {ScanResultId} non trouv√© en base", scanResultId);
                return;
            }

            logger.LogInformation("‚úÖ [SCAN-DB] ScanResult r√©cup√©r√©: {ScanId}, Status={Status}", scanResult.ScanId, scanResult.Status);

            var website = await unitOfWork.Websites.GetByIdAsync(scanResult.WebsiteId);
            if (website == null)
            {
                logger.LogError("‚ùå [SCAN-ERROR] Website {WebsiteId} non trouv√© pour le scan {ScanId}", scanResult.WebsiteId, scanResult.ScanId);
                await UpdateScanStatus(scanResult, ScanStatus.Failed, "Site web non trouv√©", unitOfWork);
                return;
            }

            logger.LogInformation("üåê [SCAN-WEBSITE] Website trouv√©: {WebsiteName} ({WebsiteUrl}), IsActive={IsActive}", 
                website.Name, website.Url, website.IsActive);

            if (!website.IsActive)
            {
                logger.LogWarning("‚ö†Ô∏è [SCAN-WARNING] Website {WebsiteId} est inactif, arr√™t du scan", website.Id);
                await UpdateScanStatus(scanResult, ScanStatus.Failed, "Site web inactif", unitOfWork);
                return;
            }

            logger.LogInformation("üöÄ [SCAN-START] D√©marrage du scan {ScanId} pour {WebsiteUrl}", scanResult.ScanId, website.Url);

            // Mettre √† jour le statut
            logger.LogInformation("üìù [SCAN-STATUS] Passage du statut √† Running pour {ScanId}", scanResult.ScanId);
            await UpdateScanStatus(scanResult, ScanStatus.Running, null, unitOfWork);

            // Phase 1: Crawling
            logger.LogInformation("üï∑Ô∏è [SCAN-PHASE-1] D√©but crawling du site {WebsiteUrl} (MaxDepth={MaxDepth}, Subdomains={IncludeSubdomains})", 
                website.Url, website.MaxDepth, website.IncludeSubdomains);
            
            var crawlStartTime = DateTime.UtcNow;
            List<string> urls;
            
            try
            {
                urls = await webCrawler.CrawlAsync(
                    website.Url, 
                    website.MaxDepth, 
                    website.IncludeSubdomains);
                
                var crawlDuration = DateTime.UtcNow - crawlStartTime;
                logger.LogInformation("‚úÖ [SCAN-CRAWL] Crawling termin√© en {Duration}ms: {UrlCount} URLs trouv√©es", 
                    crawlDuration.TotalMilliseconds, urls.Count);
                
                // Log des premi√®res URLs pour debug
                var urlsToLog = urls.Take(5).ToList();
                logger.LogDebug("[SCAN-CRAWL-URLS] Premi√®res URLs: {Urls}", string.Join(", ", urlsToLog));
            }
            catch (Exception crawlEx)
            {
                logger.LogError(crawlEx, "‚ùå [SCAN-CRAWL-ERROR] Erreur lors du crawling de {WebsiteUrl}", website.Url);
                await UpdateScanStatus(scanResult, ScanStatus.Failed, $"Erreur crawling: {crawlEx.Message}", unitOfWork);
                return;
            }

            if (!urls.Any())
            {
                logger.LogWarning("‚ö†Ô∏è [SCAN-CRAWL-EMPTY] Aucune page accessible trouv√©e pour {WebsiteUrl}", website.Url);
                await UpdateScanStatus(scanResult, ScanStatus.Failed, "Aucune page accessible trouv√©e", unitOfWork);
                return;
            }

            // Phase 2: Analyse d'accessibilit√©
            logger.LogInformation("üîç [SCAN-PHASE-2] D√©but analyse d'accessibilit√© - {UrlCount} pages √† analyser", urls.Count);
            
            var allIssues = new List<AccessibilityIssue>();
            var pagesAnalyzed = 0;
            var maxPagesToAnalyze = Math.Min(urls.Count, 50); // Limiter √† 50 pages pour √©viter les timeouts
            var analysisStartTime = DateTime.UtcNow;

            logger.LogInformation("üìä [SCAN-ANALYSIS] Analyse limit√©e √† {MaxPages} pages sur {TotalPages} trouv√©es", 
                maxPagesToAnalyze, urls.Count);

            foreach (var url in urls.Take(maxPagesToAnalyze))
            {
                if (cancellationToken.IsCancellationRequested)
                {
                    logger.LogWarning("‚èπÔ∏è [SCAN-CANCELLED] Scan annul√© par timeout pour {ScanId}", scanResult.ScanId);
                    await UpdateScanStatus(scanResult, ScanStatus.Failed, "Scan annul√© par timeout", unitOfWork);
                    return;
                }

                try
                {
                    logger.LogDebug("üîç [SCAN-PAGE] Analyse de la page {PageNumber}/{MaxPages}: {Url}", 
                        pagesAnalyzed + 1, maxPagesToAnalyze, url);
                    
                    var pageStartTime = DateTime.UtcNow;
                    var content = await webCrawler.GetPageContentAsync(url);
                    var getContentDuration = DateTime.UtcNow - pageStartTime;
                    
                    logger.LogDebug("üìÑ [SCAN-CONTENT] Contenu r√©cup√©r√© en {Duration}ms pour {Url} ({ContentLength} chars)", 
                        getContentDuration.TotalMilliseconds, url, content?.Length ?? 0);

                    if (string.IsNullOrWhiteSpace(content))
                    {
                        logger.LogWarning("‚ö†Ô∏è [SCAN-CONTENT-EMPTY] Contenu vide pour {Url}", url);
                        pagesAnalyzed++;
                        continue;
                    }

                    var analyzeStartTime = DateTime.UtcNow;
                    var issues = await accessibilityAnalyzer.AnalyzePageAsync(url, content);
                    var analyzeDuration = DateTime.UtcNow - analyzeStartTime;
                    
                    logger.LogDebug("‚úÖ [SCAN-ANALYZE] Page analys√©e en {Duration}ms: {Url} - {IssueCount} probl√®mes trouv√©s", 
                        analyzeDuration.TotalMilliseconds, url, issues.Count);
                    
                    // Associer les probl√®mes au scan
                    foreach (var issue in issues)
                    {
                        issue.ScanResultId = scanResult.Id;
                        allIssues.Add(issue);
                    }

                    pagesAnalyzed++;
                    
                    // Mettre √† jour le progr√®s p√©riodiquement
                    if (pagesAnalyzed % 5 == 0 || pagesAnalyzed == maxPagesToAnalyze)
                    {
                        scanResult.PagesScanned = pagesAnalyzed;
                        await unitOfWork.SaveChangesAsync();
                        
                        var progressPercent = (pagesAnalyzed * 100) / maxPagesToAnalyze;
                        logger.LogInformation("üìà [SCAN-PROGRESS] Progr√®s: {PagesAnalyzed}/{MaxPages} pages ({ProgressPercent}%) - {TotalIssues} probl√®mes trouv√©s", 
                            pagesAnalyzed, maxPagesToAnalyze, progressPercent, allIssues.Count);
                    }
                }
                catch (Exception ex)
                {
                    logger.LogWarning(ex, "‚ö†Ô∏è [SCAN-PAGE-ERROR] Erreur lors de l'analyse de {Url}: {ErrorMessage}", url, ex.Message);
                    pagesAnalyzed++; // Compter m√™me en cas d'erreur pour √©viter un blocage
                    // Continuer avec les autres pages
                }
            }

            var totalAnalysisDuration = DateTime.UtcNow - analysisStartTime;
            logger.LogInformation("‚úÖ [SCAN-ANALYSIS-COMPLETE] Analyse termin√©e en {Duration}s: {PagesAnalyzed} pages, {TotalIssues} probl√®mes", 
                totalAnalysisDuration.TotalSeconds, pagesAnalyzed, allIssues.Count);

            // Sauvegarder tous les probl√®mes
            foreach (var issue in allIssues)
            {
                await unitOfWork.AccessibilityIssues.AddAsync(issue);
            }

            // Phase 3: Calcul du score
            logger.LogInformation("üßÆ [SCAN-PHASE-3] Calcul du score");
            
            var score = await accessibilityAnalyzer.CalculateScoreAsync(allIssues, pagesAnalyzed);
            var grade = await accessibilityAnalyzer.GetGradeFromScoreAsync(score);

            // Mettre √† jour les r√©sultats
            scanResult.PagesScanned = pagesAnalyzed;
            scanResult.Score = score;
            scanResult.Grade = grade;
            scanResult.TotalIssues = allIssues.Count;
            scanResult.CriticalIssues = allIssues.Count(i => i.Severity == IssueSeverity.Critical);
            scanResult.WarningIssues = allIssues.Count(i => i.Severity == IssueSeverity.Warning);
            scanResult.InfoIssues = allIssues.Count(i => i.Severity == IssueSeverity.Info);
            scanResult.CompletedAt = DateTime.SpecifyKind(DateTime.UtcNow, DateTimeKind.Utc);
            scanResult.Status = ScanStatus.Completed;

            // Mettre √† jour la date du dernier scan du site
            website.LastScanAt = DateTime.UtcNow;
            await unitOfWork.Websites.UpdateAsync(website);

            await unitOfWork.SaveChangesAsync();

            logger.LogInformation("üèÅ [SCAN-COMPLETE] Scan {ScanId} termin√© avec succ√®s. Score: {Score}/100, Grade: {Grade}", 
                scanResult.ScanId, score, grade);

            // Phase 4: G√©n√©ration du rapport PDF (en arri√®re-plan)
            _ = Task.Run(async () =>
            {
                try
                {
                    logger.LogInformation("üìÑ [SCAN-PDF] G√©n√©ration du rapport PDF pour le scan {ScanId}", scanResult.ScanId);
                    
                    // Le rapport sera g√©n√©r√© √† la demande ou lors du premier acc√®s
                    // pour optimiser les performances
                }
                catch (Exception ex)
                {
                    logger.LogError(ex, "‚ùå [SCAN-PDF-ERROR] Erreur lors de la g√©n√©ration du rapport pour le scan {ScanId}", scanResult.ScanId);
                }
            });
        }
        catch (Exception ex)
        {
            logger.LogError(ex, "‚ùå [SCAN-EXECUTION-ERROR] Erreur lors de l'ex√©cution du scan {ScanId}", scanResult?.ScanId ?? "inconnu");
            
            if (scanResult != null)
            {
                await UpdateScanStatus(scanResult, ScanStatus.Failed, $"Erreur interne: {ex.Message}", unitOfWork);
            }
        }
    }

    private async Task UpdateScanStatus(ScanResult scanResult, ScanStatus status, string? errorMessage, IUnitOfWork unitOfWork)
    {
        scanResult.Status = status;
        
        if (!string.IsNullOrWhiteSpace(errorMessage))
        {
            scanResult.ErrorMessage = errorMessage;
        }

        if (status == ScanStatus.Failed || status == ScanStatus.Completed)
        {
            scanResult.CompletedAt = DateTime.SpecifyKind(DateTime.UtcNow, DateTimeKind.Utc);
        }

        await unitOfWork.ScanResults.UpdateAsync(scanResult);
        await unitOfWork.SaveChangesAsync();
    }
}